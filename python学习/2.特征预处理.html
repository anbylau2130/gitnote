<attachment contenteditable="false" data-atts="%5B%5D" data-aid=".atts-f42faa86-96c0-4bbe-8e63-d48aed40a8ee"></attachment><h1>2.特征预处理2.特征预处理</h1><p>MarkdownHTML</p><p># 特征处理</p><p><br></p><p>通过特定的统计方法(数学方法)将数据转换成算法要求的数据</p><p>## 数值类型 标准缩放</p><p>- 归一化 </p><p>- 标准化</p><p>- 缺失化</p><p><br></p><p>## 类别型数据</p><p>-  one-hot编码</p><p>## 时间类型 </p><p>-  时间切片</p><p><br></p><p># sklearn特征处理API</p><p><br></p><p> * sklearn.preprocessing</p><p>## 归一化</p><p>**特点**：通过对原始数据进行变化把&lt;font color="red"&gt;数据映射到[0-1]之间&lt;/font&gt;</p><p>**目的**：使得某一个特征不会影响整个结果</p><p>**缺点**：当数据有异常时，最大值和最小值对数据预测的准确的影响较大 ，只适合传统精确小数据场景</p><p><br></p><p><br></p><p>![](2.特征预处理_files/5c49310a3f51ef608e000000.png)</p><p><br></p><p>![](2.特征预处理_files/5c495b743f51ef608e000001.png)</p><p><br></p><p><br></p><p>### API</p><p><br></p><p>**sklearn归一化API**：sklearn.preprocessing.MinMaxScaler</p><p><br></p><p>#### MinMaxScalar(feature_range(0,1),...)</p><p>- 每个特征缩放到给定范围（默认[0-1]）</p><p><br></p><p>####  MinMaxScaler.fit_transform(X)</p><p>- X：numpy array格式的数据[n_samples,n_features]</p><p>- 返回值:转换后的形状相同的array</p><p><br></p><p><br></p><p>```</p><p>from sklearn.preprocessing import MinMaxScaler</p><p> mm = MinMaxScaler(feature_range=(3,4))</p><p>data = [</p><p>    [90, 2, 40, 30],</p><p>    [60, 4, 30, 100],</p><p>    [75, 3, 30, 50]</p><p>]</p><p><br></p><p>result = mm.fit_transform(data)</p><p>print(result)</p><p>```</p><p>![](2.特征预处理_files/5c4965e83f51ef608e000002.png)</p><p><br></p><p>## 标准化</p><p>**特点**：通过对原始数据进行变换把数据变换到&lt;font color="red"&gt;均值为0，方差为1&lt;/font&gt;范围内</p><p>**优点**：在数据比较多的时候比较稳定</p><p>如果出现异常点，由于具有一定数据量，少量的异常点对于平均值的影响并不大，从而方差变化较小</p><p>![](2.特征预处理_files/5c49748e3f51ef608e000004.png)</p><p><br></p><p>### API </p><p>标准化 API：sklearn.preprocessing.StandardScaler</p><p><br></p><p>StandardScaler(...)</p><p><br></p><p>#### StandardScaler.fit_transform(X)</p><p>- x:numpy array格式的数据[n_samples,n_features]</p><p>- 返回值:转换后的形状相同的array</p><p><br></p><p>#### StandardScaler.mean_</p><p>- 原始数据中每列特征的平均值</p><p><br></p><p>#### StandardScaler.std_</p><p>- 原始数据每列特征的方差</p><p> </p><p>```</p><p>from sklearn.preprocessing import  StandardScaler</p><p><br></p><p>ss=StandardScaler()</p><p>data=[</p><p>    [1,4,9],</p><p>    [4,8,2],</p><p>    [2,6,7]</p><p>]</p><p>result=ss.fit_transform(data)</p><p>print(result)</p><p>print(ss.mean_)</p><p>print(ss.scale_)</p><p>```</p><p>![](2.特征预处理_files/5c497a7e3f51ef608e000006.png)</p><p><br></p><p>## 缺失值处理</p><p><br></p><p>### 删除</p><p><br></p><p>删除会导致数据减少，不建议删除操作</p><p><br></p><p>### 插补</p><p><br></p><p>API：sklearn.preprocessing.Imputer(中值填补，中位数 填补)</p><p><br></p><p>Imputer(missing_values="NaN",strategy="mean",axis=0)</p><p><br></p><p>#### Imputer.fit_transform(X)</p><p>- x:numpy array格式数据[n_samples,n_features]</p><p>- 返回值：转换后的形状相同的array</p><p><br></p><p>```</p><p>from sklearn.preprocessing import Imputer</p><p>im=Imputer(missing_values="NaN",strategy="mean",axis=0)</p><p>data=[</p><p>    [1,2,3,2,5],</p><p>    [2,3,4,np.nan,6],</p><p>    [3,4,5,6,7]</p><p>]</p><p>result=im.fit_transform(data)</p><p>print(result)</p><p>```</p><p>![](2.特征预处理_files/5c497efd3f51ef608e000007.png)</p><p><br></p><p>## 数据降维</p><p>冗余：部分特征的相关度，容易小号计算性能</p><p>噪声：部分特征对预测结果有影响</p><p><br></p><p>### 特征选择</p><p>    主要方法：</p><p>    Filter（过滤式）：varlanceThreshold</p><p>    Embedded（嵌入式）：正则化，决策树</p><p>    Wrapper（包裹式）</p><p><br></p><p>    </p><p><br></p><p>#### Filter</p><p>类库：sklearn.feature_selection.VarianceThreshold</p><p><br></p><p>##### VarianceThreshold(threshold=0.0)</p><p>删除所有低方差特征</p><p><br></p><p>##### Vaiance.fit_transform(X)</p><p><br></p><p>- X:numpy array格式的数据[n_samples,n_features]</p><p><br></p><p>- 返回值：训练集差异低于threshold的特征将被删除</p><p><br></p><p>- 默认值式保留所有非零方差特征，即删除所有样本中具有相同值的特征</p><p><br></p><p>```</p><p>    from sklearn.feature_selection import VarianceThreshold</p><p>    selector = VarianceThreshold()</p><p>    X = [</p><p>        [0, 2, 0, 3],</p><p>        [0, 1, 4, 3], </p><p>        [0, 1, 1, 3]</p><p>    ]</p><p>    data=selector.fit_transform(X)</p><p>    print(data)</p><p>```</p><p>[[2 0]</p><p> [1 4]</p><p> [1 1]]</p><p> </p><p><br></p><p>### 主成分分析</p><p>![](2.特征预处理_files/5c4a6afcee58b172b8000000.png)</p><p>&lt;font color="red"&gt;当特征数量达到上百的时候，考虑数据的简化&lt;/font&gt;</p><p><br></p><p>&lt;font color="red"&gt;PCA本质&lt;/font&gt;：一种分析，简化数据集的技术</p><p>![](2.特征预处理_files/5c4a6c85ee58b172b8000001.png)</p><p>&lt;font color="red"&gt;目的&lt;/font&gt;：数据维数压缩，尽可能降低原数据的维数，损失少量信息</p><p>&lt;font color="red"&gt;作用&lt;/font&gt;：可以削减回归分析或者聚类分析中特征的数量</p><p><br></p><p>类库：sklearn.decomposition.PCA</p><p><br></p><p>#### PCA API</p><p>##### PCA(n_components=None)</p><p>- n_compoents </p><p> - 小数：的范围在0-1之间一般情况下 保留数据的90%-95%</p><p> - 整数：减少到的特征数量，一般不指定证书</p><p>- 将数据分解为低维数空间</p><p>##### PCA.fit_transform(X)</p><p>- X:numpy array格式的数据[n_samples,n_features]</p><p>- 返回值：转换后指定维度的array</p><p><br></p><p><br></p><p>```</p><p>    from sklearn.decomposition import PCA</p><p>    X=[</p><p>        [2, 8,4,5],</p><p>        [6,3,0,8],</p><p>        [3, 4,9,1]</p><p>    ]</p><p>    p=PCA(n_components=0.9)</p><p>    data=p.fit_transform(X)</p><p>    print(data)</p><p>```</p><p>&lt;font color=red&gt;这些数据保留了原始数据90%的特征&lt;/font&gt;</p><p>![](2.特征预处理_files/5c4a705fee58b172b8000002.png)</p><p><br></p><p><br></p><p># 数据类型</p><p>## 离散性数据</p><p>由记录不同类别个体的数目所得到的数据,又称计数类型,所有这些数据全部都是整数，而且不能再细分，也不能进一步提高他们的精度</p><p><br></p><p><br></p><p>## 连续性数据</p><p>变量可以在某个返回内取任一数，即变量的取值可以是连续的，如：长度，时间，质量值等，这类证书通常是非整数，含又小数部分。</p><p><br></p><p>注意：离散型是区间内不可分，连续型是区间内可分</p><p><br></p><p>![](2.特征预处理_files/5c4ac260ee58b172b8000003.png)</p><p><br></p><p>## 监督学习</p><p>- 有目标值的预测</p><p>## 无监督学习</p><p>- 没有目标值</p><p><br></p><p>分类：目标值离散型</p><p>回归：目标值连续型 预测数据</p><p><br></p><p><br></p><p># 机器学习开发流程</p><p>![](2.特征预处理_files/5c4ac531ee58b172b8000004.png)</p><p><br></p><pre class="ql-syntax" spellcheck="false">![](2.特征预处理_files/5c4ad2178a018a2525000001.png)  # 特征处理

通过特定的统计方法(数学方法)将数据转换成算法要求的数据
## 数值类型 标准缩放
- 归一化 
- 标准化
- 缺失化

## 类别型数据
-  one-hot编码
## 时间类型 
-  时间切片

# sklearn特征处理API

 * sklearn.preprocessing
## 归一化
**特点**：通过对原始数据进行变化把数据映射到[0-1]之间
**目的**：使得某一个特征不会影响整个结果
**缺点**：当数据有异常时，最大值和最小值对数据预测的准确的影响较大 ，只适合传统精确小数据场景


![](2.特征预处理_files/5c49310a3f51ef608e000000.png)

![](2.特征预处理_files/5c495b743f51ef608e000001.png)


### API

**sklearn归一化API**：sklearn.preprocessing.MinMaxScaler

#### MinMaxScalar(feature_range(0,1),...)
- 每个特征缩放到给定范围（默认[0-1]）

####  MinMaxScaler.fit_transform(X)
- X：numpy array格式的数据[n_samples,n_features]
- 返回值:转换后的形状相同的array


```
from sklearn.preprocessing import MinMaxScaler
 mm = MinMaxScaler(feature_range=(3,4))
data = [
    [90, 2, 40, 30],
    [60, 4, 30, 100],
    [75, 3, 30, 50]
]

result = mm.fit_transform(data)
print(result)
```
![](2.特征预处理_files/5c4965e83f51ef608e000002.png)

## 标准化
**特点**：通过对原始数据进行变换把数据变换到均值为0，方差为1范围内
**优点**：在数据比较多的时候比较稳定
如果出现异常点，由于具有一定数据量，少量的异常点对于平均值的影响并不大，从而方差变化较小
![](2.特征预处理_files/5c49748e3f51ef608e000004.png)

### API 
标准化 API：sklearn.preprocessing.StandardScaler

StandardScaler(...)

#### StandardScaler.fit_transform(X)
- x:numpy array格式的数据[n_samples,n_features]
- 返回值:转换后的形状相同的array

#### StandardScaler.mean_
- 原始数据中每列特征的平均值

#### StandardScaler.std_
- 原始数据每列特征的方差
 
```
from sklearn.preprocessing import  StandardScaler

ss=StandardScaler()
data=[
    [1,4,9],
    [4,8,2],
    [2,6,7]
]
result=ss.fit_transform(data)
print(result)
print(ss.mean_)
print(ss.scale_)
```
![](2.特征预处理_files/5c497a7e3f51ef608e000006.png)

## 缺失值处理

### 删除

删除会导致数据减少，不建议删除操作

### 插补

API：sklearn.preprocessing.Imputer(中值填补，中位数 填补)

Imputer(missing_values="NaN",strategy="mean",axis=0)

#### Imputer.fit_transform(X)
- x:numpy array格式数据[n_samples,n_features]
- 返回值：转换后的形状相同的array

```
from sklearn.preprocessing import Imputer
im=Imputer(missing_values="NaN",strategy="mean",axis=0)
data=[
    [1,2,3,2,5],
    [2,3,4,np.nan,6],
    [3,4,5,6,7]
]
result=im.fit_transform(data)
print(result)
```
![](2.特征预处理_files/5c497efd3f51ef608e000007.png)

## 数据降维
冗余：部分特征的相关度，容易小号计算性能
噪声：部分特征对预测结果有影响

### 特征选择
    主要方法：
    Filter（过滤式）：varlanceThreshold
    Embedded（嵌入式）：正则化，决策树
    Wrapper（包裹式）

    

#### Filter
类库：sklearn.feature_selection.VarianceThreshold

##### VarianceThreshold(threshold=0.0)
删除所有低方差特征

##### Vaiance.fit_transform(X)

- X:numpy array格式的数据[n_samples,n_features]

- 返回值：训练集差异低于threshold的特征将被删除

- 默认值式保留所有非零方差特征，即删除所有样本中具有相同值的特征

```
    from sklearn.feature_selection import VarianceThreshold
    selector = VarianceThreshold()
    X = [
        [0, 2, 0, 3],
        [0, 1, 4, 3], 
        [0, 1, 1, 3]
    ]
    data=selector.fit_transform(X)
    print(data)
```
[[2 0]
 [1 4]
 [1 1]]
 

### 主成分分析
![](2.特征预处理_files/5c4a6afcee58b172b8000000.png)
当特征数量达到上百的时候，考虑数据的简化

PCA本质：一种分析，简化数据集的技术
![](2.特征预处理_files/5c4a6c85ee58b172b8000001.png)
目的：数据维数压缩，尽可能降低原数据的维数，损失少量信息
作用：可以削减回归分析或者聚类分析中特征的数量

类库：sklearn.decomposition.PCA

#### PCA API
##### PCA(n_components=None)
- n_compoents 
 - 小数：的范围在0-1之间一般情况下 保留数据的90%-95%
 - 整数：减少到的特征数量，一般不指定证书
- 将数据分解为低维数空间
##### PCA.fit_transform(X)
- X:numpy array格式的数据[n_samples,n_features]
- 返回值：转换后指定维度的array


```
    from sklearn.decomposition import PCA
    X=[
        [2, 8,4,5],
        [6,3,0,8],
        [3, 4,9,1]
    ]
    p=PCA(n_components=0.9)
    data=p.fit_transform(X)
    print(data)
```
这些数据保留了原始数据90%的特征
![](2.特征预处理_files/5c4a705fee58b172b8000002.png)


# 数据类型
## 离散性数据
由记录不同类别个体的数目所得到的数据,又称计数类型,所有这些数据全部都是整数，而且不能再细分，也不能进一步提高他们的精度


## 连续性数据
变量可以在某个返回内取任一数，即变量的取值可以是连续的，如：长度，时间，质量值等，这类证书通常是非整数，含又小数部分。

注意：离散型是区间内不可分，连续型是区间内可分

![](2.特征预处理_files/5c4ac260ee58b172b8000003.png)

## 监督学习
- 有目标值的预测
## 无监督学习
- 没有目标值

分类：目标值离散型
回归：目标值连续型 预测数据


# 机器学习开发流程
![](2.特征预处理_files/5c4ac531ee58b172b8000004.png)

</pre><p>![](2.特征预处理_files/5c4ad2178a018a2525000001.png)  </p><p> function init() { markdownToHtml(document.getElementById('leanote-content-markdown').value, document.getElementById('leanote-content-html'), function(html) { // 解析后执行 if(window.markdownParsed) { window.markdownParsed(html); } }); var $m = document.getElementById('tab-markdown'); var $h = document.getElementById('tab-html'); var $cc = document.getElementById('content-container'); function toggleToHtml(isToHtml) { $cc.className = isToHtml ? 'content-container html' : 'content-container'; } $m.addEventListener('click', function() { toggleToHtml(false); }); $h.addEventListener('click', function() { toggleToHtml(true); }); } // 如果不要自动解析html, notParseMarkdown在leanote-markdown.js中定义 if(!window.notParseMarkdown) { init(); } </p><p><br></p>