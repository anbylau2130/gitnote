# 特征工程

特征工程是<font color="red">将原始数据 转换为更好的代表预测模型的潜在问题的特征</font>的过程,从而<font color="red">提高了对未知数据的预测准确性</font>

----------
# scikitlearn库

## 特征抽取API
sklearn.feature_extraction

## 字典数据抽取

作用：对字典数据进行特征值化

类: sklearn.feature_extraction.DictVectorizer

### DictVertorizer语法
DictVectorizer(sparse=True,...)

- DictVectorizer.fit_transform(X)
    -  x:字典或者包含字典的迭代器
    -  返回值：返回sparse矩阵
- DictVectorizer.inverse_transform(X)
    - x:arrary数据或者sparse矩阵
    - 返回值：转换之前数据格式
- DictVectorizer.get_feature_names()
    - 返回类别名称
- DictVectorizer.transform(X)
    - 按照原先的标准转换

## one-hot编码

  将字符串转换为数值

```
from  sklearn.feature_extraction import DictVectorizer

orgdata=[
    {'name':"hiuyeung","age":17,"male":"man"},
    {'name':"jessica","age":20,"male":"woman"},
    {'name':"ruby","age":25,"male":"man"},
]
dict=DictVectorizer(sparse=False)

data=dict.fit_transform(orgdata)

print(dict.get_feature_names())

print(data)

```
![title](https://raw.githubusercontent.com/anbylau2130/gitnoteImages/master/gitnoteImages/2019/04/02/1554172045197-1554172045199.png)

## 文本特征抽取
作用：对文本数据进行特征值化
类：sklearn.feature_extraction.txt.CountVectorizer


### CountVectorizer 语法
- CountVectorizer() 
<font color="red">
1.返回词频矩阵
2对单个次不进行统计
3.只支持英文，中文需要做分词处理
</font>

- CountVectorizer.fit_transform(X)
    - x:文本或者包含文本字符串的可迭代对象
    - 返回值：返回sparse矩阵
- CountVectorizer.inverse_transform(X)
    - x:array数组或者sparse矩阵
    - 返回值：转换之前的数据格式
- CountVectorizer.get_feature_names()
    - 返回：单词列表

#### 英文
```
from sklearn.feature_extraction.text import CountVectorizer

orgdata=[
    "hiuyeung is is a good guy!",
    "I like python .",
    "python is easy.",
    "jessica is nice girl~"
]
cv =CountVectorizer()
data= cv.fit_transform(orgdata)
print(cv.get_feature_names())
print(data.toarray())


```
![title](https://raw.githubusercontent.com/anbylau2130/gitnoteImages/master/gitnoteImages/2019/04/02/1554172074775-1554172074777.png)


#### 中文
使用jieba分词将字符串分割后进行统计
```
import jieba
from sklearn.feature_extraction.text import CountVectorizer

con1=jieba.cut("我种下一颗种子，终于长出了果实，今天是个伟大日子,摘下星星送给你，拽下月亮送给你，让太阳每天为你升起,变成蜡烛燃烧自己，只为照亮你，把我一切都献给你，只要你欢喜,你让我每个明天都 变得有意义，生命虽短爱你永远，不离不弃,你是我的小呀小苹果儿   怎么爱你都不嫌多,红红的小脸儿温暖我的心窝   点亮我生命的火  火火火火,你是我的小呀小苹果儿   就像天边最美的云朵,春天又来到了花开满山坡   种下希望就会收获,从不觉得你讨厌，你的一切都喜欢   有你的每天都新鲜,有你阳光更灿烂，有你黑夜不黑暗   你是白云我是蓝天,春天和你漫步在盛开的 花丛间,夏天夜晚陪你一起看 星星眨眼,秋天黄昏与你徜徉在 金色麦田,冬天雪花飞舞有你 更加温暖 ,你是我的小呀小苹果儿   怎么爱你都不嫌多,红红的小脸儿温暖我的心窝   点亮我生命的火  火火火,你是我的小呀小苹果儿   就像天边最美的云朵,春天又来到了花开满山坡   种下希望就会收获,你是我的小呀小苹果儿   怎么爱你都不嫌多,红红的小脸儿温暖我的心窝   点亮我生命的火  火火火火,你是我的小呀小苹果儿   就像天边最美的云朵,春天又来到了花开满山坡   种下希望就会收获")

content1=list(con1)

c1=" ".join(content1)

cv =CountVectorizer()
data= cv.fit_transform([c1])
print(cv.get_feature_names())
print(data.toarray())
```

![title](https://raw.githubusercontent.com/anbylau2130/gitnoteImages/master/gitnoteImages/2019/04/02/1554172119797-1554172119800.png)

### tf idf 语法


![title](https://raw.githubusercontent.com/anbylau2130/gitnoteImages/master/gitnoteImages/2019/04/02/1554172199223-1554172199227.png)

TF-IDF 的主要思想是：如果某个词或短语再一片文章中出现的频率高，并且再其他文章中很少出现，则任务此词或者短语具有很好的分类区别能力，适合用来 分类.
TF-IDF的作用：用以评估一字词对于一个文件集或一个语料库中的其他一份文件的重要程度

类：sklearn.feature_extraction.text.TfidfVectorizer

- TfidfVectorizer(stop_words=None,...)
返回词的权重矩阵
- TfidfVectorizer.fit_transform(X)
    - x:文本或者包含文本字符串的可迭代对象
    - 返回值：返回sparse矩阵
- TfidfVectorizer.inverse_transform(X)
    - x:array数组或者sparse矩阵
    - 返回值：转换之前数据格式
- TfidfVectorizer.get_feature_names()
    - 返回值：单词列表
    
```
import jieba
from sklearn.feature_extraction.text import TfidfVectorizer

con1=jieba.cut("我种下一颗种子，终于长出了果实，今天是个伟大日子,摘下星星送给你，拽下月亮送给你，让太阳每天为你升起,变成蜡烛燃烧自己，只为照亮你，把我一切都献给你，只要你欢喜,你让我每个明天都 变得有意义，生命虽短爱你永远，不离不弃,你是我的小呀小苹果儿   怎么爱你都不嫌多,红红的小脸儿温暖我的心窝   点亮我生命的火  火火火火,你是我的小呀小苹果儿   就像天边最美的云朵,春天又来到了花开满山坡   种下希望就会收获,从不觉得你讨厌，你的一切都喜欢   有你的每天都新鲜,有你阳光更灿烂，有你黑夜不黑暗   你是白云我是蓝天,春天和你漫步在盛开的 花丛间,夏天夜晚陪你一起看 星星眨眼,秋天黄昏与你徜徉在 金色麦田,冬天雪花飞舞有你 更加温暖 ,你是我的小呀小苹果儿   怎么爱你都不嫌多,红红的小脸儿温暖我的心窝   点亮我生命的火  火火火,你是我的小呀小苹果儿   就像天边最美的云朵,春天又来到了花开满山坡   种下希望就会收获,你是我的小呀小苹果儿   怎么爱你都不嫌多,红红的小脸儿温暖我的心窝   点亮我生命的火  火火火火,你是我的小呀小苹果儿   就像天边最美的云朵,春天又来到了花开满山坡   种下希望就会收获")

content1=list(con1)

c1=" ".join(content1)


tf =TfidfVectorizer()
data= tf.fit_transform([c1])
print(tf.get_feature_names())
print(data.toarray())

data.max()

```
![title](https://raw.githubusercontent.com/anbylau2130/gitnoteImages/master/gitnoteImages/2019/04/02/1554172145909-1554172145916.png)