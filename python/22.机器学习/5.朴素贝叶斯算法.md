# 不需要调参数

# 联合概率
包含多个条件，且所有条件同时成立的概率
![](https://github.com/anbylau2130/gitnote/blob/master/python/22.机器学习/images/5c4fb660ad653a20c3000000.png)
# 条件概率
![](https://github.com/anbylau2130/gitnote/blob/master/python/22.机器学习/images/5c4fb669ad653a20c3000001.png)


# 朴素贝叶斯 
特征是条件独立时才能使用

# 朴素贝叶斯公式
![](https://github.com/anbylau2130/gitnote/blob/master/python/22.机器学习/images/5c4fb8a7ad653a20c3000002.png)

![](https://github.com/anbylau2130/gitnote/blob/master/python/22.机器学习/images/5c4fb992ad653a20c3000003.png)



# 解决概率为0的情况
![](https://github.com/anbylau2130/gitnote/blob/master/python/22.机器学习/images/5c4fbb6bad653a20c3000004.png)


# 朴素贝叶斯 API
## sklearn.naive_bayes.MultinomialNB

### MultinomialNB(alpha=1.0)
- 朴素贝叶斯分类
- alpha:拉普拉斯平滑系数

训练集误差大，结构肯定不准确



# 优点
- 朴素贝叶斯是模型发源于古典数据理论，有稳定的分类效率
- 对缺失数据不太敏感，算法也比较简单。常用于文章分类
- 分类准确度高，速度快

# 缺点
由于使用了样本属性独立性的假设，所以如果样本属性有关联时其效果不好


# 案例
```
from sklearn.naive_bayes import MultinomialNB
from sklearn.datasets import fetch_20newsgroups
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
news=fetch_20newsgroups(subset="all")
# 分割数据集
x_trains,x_test,y_trains,y_test=train_test_split(news.data,news.target)

# tf idf进行分词
tf=TfidfVectorizer()

x_trains=tf.fit_transform(x_trains)

x_test=tf.fit_transform(x_test)

# 朴素贝叶斯 进行数据训练
mlt=MultinomialNB(alpha=1.0)
# 获取预测结果
y_predict=mlt.fit(x_trains,y_trains)
# 统计预测准确率
p=mlt.score(x_test,y_test)
print(p)

```


 